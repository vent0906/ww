{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vent0906/ww/blob/main/GCN_GraphSAGE_Tutorial_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Code Directory\n",
        " 1. Install required dependencies (PyG & DGL)\n",
        " 2. Load and inspect MUTAG dataset using PyG\n",
        " 3. Prepare DataLoader for training/testing\n",
        " 4. Define GCNClassifier using GCNConv\n",
        " 5. Train and evaluate GCN model\n",
        " 6. Load and inspect Cora dataset using DGL\n",
        " 7. Generate train/test splits for link prediction\n",
        " 8. Define GraphSAGE model with DGL\n",
        " 9. Define DotProductPredictor and MLPPredictor\n",
        " 10. Train GraphSAGE model and evaluate AUC"
      ],
      "metadata": {
        "id": "JBN3TnKS6So3"
      },
      "id": "JBN3TnKS6So3"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8fcc49e8",
      "metadata": {
        "id": "8fcc49e8"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Step 1: Install required dependencies (PyG & DGL)\n",
        "\n",
        "import torch\n",
        "print(f\"Using torch version: {torch.__version__}\")\n",
        "\n",
        "# Install PyTorch Geometric dependencies\n",
        "!pip install torch-scatter -f https://data.pyg.org/whl/torch-$(python3 -c \"import torch; print(torch.__version__.split('+')[0])\").html\n",
        "!pip install torch-sparse -f https://data.pyg.org/whl/torch-$(python3 -c \"import torch; print(torch.__version__.split('+')[0])\").html\n",
        "!pip install torch-geometric\n",
        "!pip install dgl\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "31f46fd8",
      "metadata": {
        "id": "31f46fd8"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Step 2: Load and inspect MUTAG dataset using PyG\n",
        "\n",
        "from torch_geometric.datasets import TUDataset\n",
        "\n",
        "graph_dataset = TUDataset(root='data/TUDataset', name='MUTAG')\n",
        "print(f'Dataset: {graph_dataset}')\n",
        "print(f'Number of graphs: {len(graph_dataset)}')\n",
        "print(f'Number of node features: {graph_dataset.num_features}')\n",
        "print(f'Number of classes: {graph_dataset.num_classes}')\n",
        "\n",
        "sample_graph = graph_dataset[0]\n",
        "print(sample_graph)\n",
        "print(f'Nodes: {sample_graph.num_nodes}, Edges: {sample_graph.num_edges}')\n",
        "print(f'Average node degree: {sample_graph.num_edges / sample_graph.num_nodes:.2f}')\n",
        "print(f'Isolated nodes: {sample_graph.has_isolated_nodes()}')\n",
        "print(f'Self-loops: {sample_graph.has_self_loops()}')\n",
        "print(f'Undirected: {sample_graph.is_undirected()}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "35529b7d",
      "metadata": {
        "id": "35529b7d"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Step 3: Prepare DataLoader for training/testing\n",
        "\n",
        "import torch\n",
        "from torch_geometric.loader import DataLoader\n",
        "\n",
        "torch.manual_seed(12345)\n",
        "graph_dataset = graph_dataset.shuffle()\n",
        "train_subset = graph_dataset[:150]\n",
        "test_subset = graph_dataset[150:]\n",
        "\n",
        "train_loader = DataLoader(train_subset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_subset, batch_size=64, shuffle=False)\n",
        "\n",
        "print(f'Training graphs: {len(train_subset)}, Test graphs: {len(test_subset)}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a1a268e7",
      "metadata": {
        "id": "a1a268e7"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Step 4: Define GCNClassifier using GCNConv\n",
        "\n",
        "import torch.nn.functional as F\n",
        "from torch.nn import Linear\n",
        "from torch_geometric.nn import GCNConv, global_mean_pool\n",
        "\n",
        "class GCNClassifier(torch.nn.Module):\n",
        "    def __init__(self, hidden_dim):\n",
        "        super().__init__()\n",
        "        torch.manual_seed(12345)\n",
        "        self.gcn1 = GCNConv(graph_dataset.num_node_features, hidden_dim)\n",
        "        self.gcn2 = GCNConv(hidden_dim, hidden_dim)\n",
        "        self.gcn3 = GCNConv(hidden_dim, hidden_dim)\n",
        "        self.output_layer = Linear(hidden_dim, graph_dataset.num_classes)\n",
        "\n",
        "    def forward(self, x, edge_index, batch):\n",
        "        x = F.relu(self.gcn1(x, edge_index))\n",
        "        x = F.relu(self.gcn2(x, edge_index))\n",
        "        x = self.gcn3(x, edge_index)\n",
        "        x = global_mean_pool(x, batch)\n",
        "        x = F.dropout(x, p=0.5, training=self.training)\n",
        "        return self.output_layer(x)\n",
        "\n",
        "classifier_net = GCNClassifier(hidden_dim=64)\n",
        "print(classifier_net)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "66c7a223",
      "metadata": {
        "id": "66c7a223"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Step 5: Train and evaluate GCN model\n",
        "\n",
        "optimizer = torch.optim.Adam(classifier_net.parameters(), lr=0.01)\n",
        "loss_function = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "def run_training():\n",
        "    classifier_net.train()\n",
        "    for batch in train_loader:\n",
        "        pred = classifier_net(batch.x, batch.edge_index, batch.batch)\n",
        "        loss = loss_function(pred, batch.y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "def evaluate(loader):\n",
        "    classifier_net.eval()\n",
        "    correct = 0\n",
        "    for batch in loader:\n",
        "        pred = classifier_net(batch.x, batch.edge_index, batch.batch)\n",
        "        predicted = pred.argmax(dim=1)\n",
        "        correct += int((predicted == batch.y).sum())\n",
        "    return correct / len(loader.dataset)\n",
        "\n",
        "for epoch in range(1, 51):\n",
        "    run_training()\n",
        "    train_acc = evaluate(train_loader)\n",
        "    test_acc = evaluate(test_loader)\n",
        "    if epoch % 5 == 0:\n",
        "        print(f'Epoch {epoch:03d}: Train Acc = {train_acc:.4f}, Test Acc = {test_acc:.4f}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7a425035",
      "metadata": {
        "id": "7a425035"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Step 6: Load and inspect Cora dataset using DGL\n",
        "\n",
        "import dgl\n",
        "import numpy as np\n",
        "import scipy.sparse as sp\n",
        "import dgl.data\n",
        "\n",
        "cora_dataset = dgl.data.CoraGraphDataset()\n",
        "cora_graph = cora_dataset[0]\n",
        "print(cora_graph)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4137ac85",
      "metadata": {
        "id": "4137ac85"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Step 7: Generate train/test splits for link prediction\n",
        "\n",
        "u, v = cora_graph.edges()\n",
        "eids = np.random.permutation(np.arange(cora_graph.number_of_edges()))\n",
        "test_size = int(len(eids) * 0.1)\n",
        "\n",
        "test_pos_u, test_pos_v = u[eids[:test_size]], v[eids[:test_size]]\n",
        "train_pos_u, train_pos_v = u[eids[test_size:]], v[eids[test_size:]]\n",
        "\n",
        "adj = sp.coo_matrix((np.ones(len(u)), (u.numpy(), v.numpy())))\n",
        "adj_neg = 1 - adj.todense() - np.eye(cora_graph.number_of_nodes())\n",
        "neg_u, neg_v = np.where(adj_neg != 0)\n",
        "\n",
        "neg_eids = np.random.choice(len(neg_u), cora_graph.number_of_edges())\n",
        "test_neg_u, test_neg_v = neg_u[neg_eids[:test_size]], neg_v[neg_eids[:test_size]]\n",
        "train_neg_u, train_neg_v = neg_u[neg_eids[test_size:]], neg_v[neg_eids[test_size:]]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "910577c4",
      "metadata": {
        "id": "910577c4"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Step 8: Define GraphSAGE model with DGL\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from dgl.nn import SAGEConv\n",
        "\n",
        "class GraphSAGE(nn.Module):\n",
        "    def __init__(self, in_feats, hidden_feats):\n",
        "        super().__init__()\n",
        "        self.conv1 = SAGEConv(in_feats, hidden_feats, 'mean')\n",
        "        self.conv2 = SAGEConv(hidden_feats, hidden_feats, 'mean')\n",
        "\n",
        "    def forward(self, g, x):\n",
        "        h = self.conv1(g, x)\n",
        "        h = F.relu(h)\n",
        "        h = self.conv2(g, h)\n",
        "        return h\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "44b84e43",
      "metadata": {
        "id": "44b84e43"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Step 9: Define DotProductPredictor and MLPPredictor\n",
        "\n",
        "import dgl.function as fn\n",
        "\n",
        "class DotProductPredictor(nn.Module):\n",
        "    def forward(self, g, h):\n",
        "        with g.local_scope():\n",
        "            g.ndata['h'] = h\n",
        "            g.apply_edges(fn.u_dot_v('h', 'h', 'score'))\n",
        "            return g.edata['score'][:, 0]\n",
        "\n",
        "class MLPPredictor(nn.Module):\n",
        "    def __init__(self, h_feats):\n",
        "        super().__init__()\n",
        "        self.W1 = nn.Linear(h_feats * 2, h_feats)\n",
        "        self.W2 = nn.Linear(h_feats, 1)\n",
        "\n",
        "    def apply_edges(self, edges):\n",
        "        h = torch.cat([edges.src['h'], edges.dst['h']], 1)\n",
        "        return {'score': self.W2(F.relu(self.W1(h))).squeeze(1)}\n",
        "\n",
        "    def forward(self, g, h):\n",
        "        with g.local_scope():\n",
        "            g.ndata['h'] = h\n",
        "            g.apply_edges(self.apply_edges)\n",
        "            return g.edata['score']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "57ca4b2b",
      "metadata": {
        "id": "57ca4b2b"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Step 10: Train GraphSAGE model and evaluate AUC\n",
        "\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "train_graph = dgl.remove_edges(cora_graph, eids[:test_size])\n",
        "train_pos_g = dgl.graph((train_pos_u, train_pos_v), num_nodes=cora_graph.number_of_nodes())\n",
        "train_neg_g = dgl.graph((train_neg_u, train_neg_v), num_nodes=cora_graph.number_of_nodes())\n",
        "test_pos_g = dgl.graph((test_pos_u, test_pos_v), num_nodes=cora_graph.number_of_nodes())\n",
        "test_neg_g = dgl.graph((test_neg_u, test_neg_v), num_nodes=cora_graph.number_of_nodes())\n",
        "\n",
        "model = GraphSAGE(train_graph.ndata['feat'].shape[1], 16)\n",
        "predictor = DotProductPredictor()\n",
        "\n",
        "def compute_loss(pos_score, neg_score):\n",
        "    scores = torch.cat([pos_score, neg_score])\n",
        "    labels = torch.cat([torch.ones(pos_score.shape[0]), torch.zeros(neg_score.shape[0])])\n",
        "    return F.binary_cross_entropy_with_logits(scores, labels)\n",
        "\n",
        "def compute_auc(pos_score, neg_score):\n",
        "    scores = torch.cat([pos_score, neg_score]).detach().numpy()\n",
        "    labels = torch.cat([torch.ones(pos_score.shape[0]), torch.zeros(neg_score.shape[0])]).numpy()\n",
        "    return roc_auc_score(labels, scores)\n",
        "\n",
        "optimizer = torch.optim.Adam(list(model.parameters()) + list(predictor.parameters()), lr=0.01)\n",
        "\n",
        "for epoch in range(100):\n",
        "    h = model(train_graph, train_graph.ndata['feat'])\n",
        "    pos_score = predictor(train_pos_g, h)\n",
        "    neg_score = predictor(train_neg_g, h)\n",
        "    loss = compute_loss(pos_score, neg_score)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if epoch % 10 == 0:\n",
        "        print(f'Epoch {epoch}, Loss: {loss.item():.4f}')\n",
        "\n",
        "with torch.no_grad():\n",
        "    h = model(train_graph, train_graph.ndata['feat'])\n",
        "    pos_score = predictor(test_pos_g, h)\n",
        "    neg_score = predictor(test_neg_g, h)\n",
        "    print('AUC:', compute_auc(pos_score, neg_score))\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}